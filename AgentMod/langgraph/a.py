from typing import TypedDict, Annotated, Sequence
import dotenv
from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage
from langchain_nvidia_ai_endpoints import ChatNVIDIA
from langgraph.graph import StateGraph, END
from AgentMod.tools.toos_map import ToolIocContainer
import os

dotenv.load_dotenv()

# 1. å®šä¹‰å·¥å…·
tool_path = r"D:\Py_Project\Langcahin\AgentMod\tools\tool_config.yaml"
ToolIocContainer.load_tool_config(tool_path)
tools = ToolIocContainer.get_tool()

# ã€é‡è¦ã€‘åˆ›å»ºä¸€ä¸ªå·¥å…·åç§°åˆ°å·¥å…·å¯¹è±¡çš„æ˜ å°„å­—å…¸ï¼Œæ–¹ä¾¿åŠ¨æ€æŸ¥æ‰¾
# è¿™æ ·å°±ä¸éœ€è¦å†™ä¸€å † if-else äº†
tool_map = {t.name: t for t in tools}

print(f"å·²åŠ è½½å·¥å…·: {list(tool_map.keys())}")

llm = ChatNVIDIA(
    base_url=os.getenv("BASE_URL"),
    model=os.getenv("MODEL_NAME"),
    api_key=os.getenv("API_KEY"),
    max_completion_tokens=2048,  # ã€å…³é”®ã€‘å¢åŠ è¾“å‡ºé•¿åº¦ï¼Œé˜²æ­¢ç”Ÿæˆä»£ç æ—¶æˆªæ–­
    temperature=0.1  # é™ä½æ¸©åº¦ï¼Œè®©ä»£ç ç”Ÿæˆæ›´ç¨³å®š
)

llm_with_tools = llm.bind_tools(tools)


# 2. å®šä¹‰ State (çŠ¶æ€)
class AgentState(TypedDict):
    messages: Sequence[BaseMessage]


# 3. å®šä¹‰èŠ‚ç‚¹å‡½æ•°
def chat_node(state: AgentState):
    messages = state["messages"]
    print(f"\n[AI æ€è€ƒä¸­...] å½“å‰å¯¹è¯è½®æ•°: {len(messages)}")

    # è°ƒç”¨ LLM
    response = llm_with_tools.invoke(messages)

    # ç®€å•æ—¥å¿—
    if response.tool_calls:
        tool_names = [tc['name'] for tc in response.tool_calls]
        print(f">> å†³å®šè°ƒç”¨å·¥å…·: {tool_names}")
    else:
        content_preview = response.content[:50] + "..." if len(response.content) > 50 else response.content
        print(f">> æœ€ç»ˆå›å¤: {content_preview}")

    return {"messages": [response]}


def tool_node(state: AgentState):
    messages = state["messages"]
    last_message = messages[-1]

    tool_outputs = []

    # éå†æ‰€æœ‰éœ€è¦è°ƒç”¨çš„å·¥å…·
    for tool_call in last_message.tool_calls:
        name = tool_call["name"]
        args = tool_call["args"]
        tool_call_id = tool_call["id"]

        print(f"   -> æ­£åœ¨æ‰§è¡Œå·¥å…·: {name}, å‚æ•°: {args}")

        # ã€æ ¸å¿ƒä¿®æ”¹ã€‘åŠ¨æ€æŸ¥æ‰¾å¹¶æ‰§è¡Œå·¥å…·
        if name in tool_map:
            try:
                target_tool = tool_map[name]
                # invoke æ–¹æ³•é€šå¸¸æ¥å—å­—å…¸ä½œä¸ºå‚æ•°
                result = target_tool.invoke(args)

                # å°†ç»“æœå°è£…ä¸º ToolMessage
                tool_outputs.append(
                    ToolMessage(content=str(result), tool_call_id=tool_call_id)
                )
                print(f"   <- å·¥å…·æ‰§è¡ŒæˆåŠŸ (è¿”å›é•¿åº¦: {len(str(result))})")
            except Exception as e:
                error_msg = f"å·¥å…·æ‰§è¡Œå‡ºé”™: {str(e)}"
                print(f"   <- é”™è¯¯: {error_msg}")
                # å³ä½¿å‡ºé”™ä¹Ÿè¦è¿”å›æ¶ˆæ¯ï¼Œè®© AI çŸ¥é“å¤±è´¥äº†ï¼Œå®ƒå¯ä»¥å°è¯•é‡è¯•
                tool_outputs.append(
                    ToolMessage(content=error_msg, tool_call_id=tool_call_id)
                )
        else:
            error_msg = f"æœªæ‰¾åˆ°åä¸º '{name}' çš„å·¥å…·ã€‚å¯ç”¨å·¥å…·: {list(tool_map.keys())}"
            print(f"   <- é”™è¯¯: {error_msg}")
            tool_outputs.append(
                ToolMessage(content=error_msg, tool_call_id=tool_call_id)
            )

    # è¿”å›åŒ…å«å·¥å…·æ‰§è¡Œç»“æœçš„æ¶ˆæ¯åˆ—è¡¨
    return {"messages": tool_outputs}


# 4. å®šä¹‰æ¡ä»¶è¾¹é€»è¾‘
def should_continue(state: AgentState):
    messages = state["messages"]
    last_message = messages[-1]

    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"
    return END


# 5. æ„å»ºå›¾
workflow = StateGraph(AgentState)

workflow.add_node("agent", chat_node)
workflow.add_node("tools", tool_node)

workflow.set_entry_point("agent")

workflow.add_conditional_edges(
    "agent",
    should_continue,
    {
        "tools": "tools",
        END: END
    }
)

workflow.add_edge("tools", "agent")

app = workflow.compile()

# 6. è¿è¡Œ
if __name__ == "__main__":
    # æµ‹è¯•ä»»åŠ¡ï¼šè¯»å–æ–‡ä»¶å¹¶å†™ä»£ç 
    task = "D:\\Py_Project\\Langcahin\\AgentMod\\images\\text.md æ–‡ä»¶æ˜¯ä¸€ä¸ªç®—æ³•é¢˜ï¼Œè¯·ä½ è¯»å–é‡Œé¢çš„å†…å®¹ï¼Œå†™ä¸€ä¸ªå®Œæ•´çš„ Python Demo (LRU ç¼“å­˜)ï¼Œä¿å­˜åˆ°åŒç›®å½•ä¸‹ã€‚"

    inputs = {"messages": [HumanMessage(content=task)]}
    config = {"configurable": {"thread_id": "lru_demo_01"}}

    print("=" * 30)
    print("å¼€å§‹è¿è¡Œ LangGraph Agent...")
    print("=" * 30)

    try:
        for event in app.stream(inputs, config):
            for key, value in event.items():
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´è¯¦ç»†çš„èŠ‚ç‚¹è¾“å‡ºç›‘æ§
                pass

        print("\n" + "=" * 30)
        print("âœ… ä»»åŠ¡æµç¨‹ç»“æŸï¼è¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç”Ÿæˆã€‚")
        print("=" * 30)

        # æ‰“å°æœ€åä¸€æ¡ AI çš„æ€»ç»“
        final_messages = value.get("messages", [])
        for msg in reversed(final_messages):
            if isinstance(msg, HumanMessage): continue
            if isinstance(msg, ToolMessage): continue
            if hasattr(msg, 'content') and msg.content:
                print(f"ğŸ¤– AI æ€»ç»“:\n{msg.content}")
                break

    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()